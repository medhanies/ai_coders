{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 10:29:06.719488: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /Users/medhaniesolomon/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd7e0e539544d64aefbc6034e166692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c01b93eb9b487396cb74f3bb21775e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ed400182024761a313d595ef47b9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5408146f9343098b4c82e1aa2bbb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51e7301f36a410285e600b98ec54080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fae643f60ec458780c21ff480feda8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /Users/medhaniesolomon/tensorflow_datasets/fashion_mnist/3.0.1.incompleteEEPMLT/fashion_mnist-train.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb882a244054bf9bd708592f7cc07af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac85ee3ef790421a9abf2dd2c7c3859c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /Users/medhaniesolomon/tensorflow_datasets/fashion_mnist/3.0.1.incompleteEEPMLT/fashion_mnist-test.t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to /Users/medhaniesolomon/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "mnist_data = tfds.load(\"fashion_mnist\")\n",
    "for item in mnist_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "# load splits into dataset with real data\n",
    "mnist_train = tfds.load(name=\"fashion_mnist\", split=\"train\")\n",
    "assert isinstance(mnist_train, tf.data.Dataset)\n",
    "print(type(mnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['image', 'label'])\n",
      "tf.Tensor(\n",
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 77]\n",
      "  [227]\n",
      "  [227]\n",
      "  [208]\n",
      "  [210]\n",
      "  [225]\n",
      "  [216]\n",
      "  [ 85]\n",
      "  [ 32]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 61]\n",
      "  [100]\n",
      "  [ 97]\n",
      "  [ 80]\n",
      "  [ 57]\n",
      "  [117]\n",
      "  [227]\n",
      "  [238]\n",
      "  [115]\n",
      "  [ 49]\n",
      "  [ 78]\n",
      "  [106]\n",
      "  [108]\n",
      "  [ 71]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 81]\n",
      "  [105]\n",
      "  [ 80]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 64]\n",
      "  [ 44]\n",
      "  [ 21]\n",
      "  [ 13]\n",
      "  [ 44]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 80]\n",
      "  [114]\n",
      "  [ 80]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [ 92]\n",
      "  [ 69]\n",
      "  [ 68]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 71]\n",
      "  [ 74]\n",
      "  [ 83]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 83]\n",
      "  [ 77]\n",
      "  [108]\n",
      "  [ 34]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 69]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 71]\n",
      "  [ 71]\n",
      "  [ 77]\n",
      "  [ 69]\n",
      "  [ 66]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 94]\n",
      "  [ 63]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 63]\n",
      "  [ 95]\n",
      "  [ 66]\n",
      "  [ 68]\n",
      "  [ 72]\n",
      "  [ 72]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 77]\n",
      "  [106]\n",
      "  [ 61]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [108]\n",
      "  [ 71]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 71]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 78]\n",
      "  [ 72]\n",
      "  [ 85]\n",
      "  [128]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 88]\n",
      "  [120]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 83]\n",
      "  [ 83]\n",
      "  [ 66]\n",
      "  [111]\n",
      "  [123]\n",
      "  [ 78]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 85]\n",
      "  [134]\n",
      "  [ 74]\n",
      "  [ 85]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 81]\n",
      "  [ 75]\n",
      "  [ 61]\n",
      "  [151]\n",
      "  [115]\n",
      "  [ 91]\n",
      "  [ 12]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 10]\n",
      "  [ 85]\n",
      "  [153]\n",
      "  [ 83]\n",
      "  [ 80]\n",
      "  [ 68]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 68]\n",
      "  [ 61]\n",
      "  [162]\n",
      "  [122]\n",
      "  [ 78]\n",
      "  [  6]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 30]\n",
      "  [ 75]\n",
      "  [154]\n",
      "  [ 85]\n",
      "  [ 80]\n",
      "  [ 71]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 49]\n",
      "  [191]\n",
      "  [132]\n",
      "  [ 72]\n",
      "  [ 15]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 58]\n",
      "  [ 66]\n",
      "  [174]\n",
      "  [115]\n",
      "  [ 66]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 78]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 66]\n",
      "  [ 49]\n",
      "  [222]\n",
      "  [131]\n",
      "  [ 77]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 69]\n",
      "  [ 55]\n",
      "  [179]\n",
      "  [139]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 80]\n",
      "  [ 64]\n",
      "  [ 55]\n",
      "  [242]\n",
      "  [111]\n",
      "  [ 95]\n",
      "  [ 44]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 74]\n",
      "  [ 57]\n",
      "  [159]\n",
      "  [180]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 64]\n",
      "  [ 72]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 55]\n",
      "  [ 66]\n",
      "  [255]\n",
      "  [ 97]\n",
      "  [108]\n",
      "  [ 49]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 74]\n",
      "  [ 66]\n",
      "  [145]\n",
      "  [153]\n",
      "  [ 72]\n",
      "  [ 83]\n",
      "  [ 58]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 80]\n",
      "  [ 30]\n",
      "  [132]\n",
      "  [255]\n",
      "  [ 37]\n",
      "  [122]\n",
      "  [ 60]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [ 69]\n",
      "  [142]\n",
      "  [180]\n",
      "  [142]\n",
      "  [ 57]\n",
      "  [ 64]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 85]\n",
      "  [ 21]\n",
      "  [185]\n",
      "  [227]\n",
      "  [ 37]\n",
      "  [143]\n",
      "  [ 63]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [ 71]\n",
      "  [136]\n",
      "  [194]\n",
      "  [126]\n",
      "  [ 46]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 38]\n",
      "  [139]\n",
      "  [185]\n",
      "  [ 60]\n",
      "  [151]\n",
      "  [ 58]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [ 81]\n",
      "  [ 74]\n",
      "  [145]\n",
      "  [177]\n",
      "  [ 78]\n",
      "  [ 49]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 72]\n",
      "  [ 63]\n",
      "  [ 80]\n",
      "  [156]\n",
      "  [117]\n",
      "  [153]\n",
      "  [ 55]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 10]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [157]\n",
      "  [163]\n",
      "  [ 61]\n",
      "  [ 55]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 71]\n",
      "  [ 60]\n",
      "  [ 98]\n",
      "  [156]\n",
      "  [132]\n",
      "  [ 58]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 13]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [157]\n",
      "  [143]\n",
      "  [ 43]\n",
      "  [ 61]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 71]\n",
      "  [ 58]\n",
      "  [ 80]\n",
      "  [157]\n",
      "  [120]\n",
      "  [ 66]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 81]\n",
      "  [ 74]\n",
      "  [156]\n",
      "  [114]\n",
      "  [ 35]\n",
      "  [ 72]\n",
      "  [ 71]\n",
      "  [ 75]\n",
      "  [ 78]\n",
      "  [ 72]\n",
      "  [ 66]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 64]\n",
      "  [ 63]\n",
      "  [165]\n",
      "  [119]\n",
      "  [ 68]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 23]\n",
      "  [ 85]\n",
      "  [ 81]\n",
      "  [177]\n",
      "  [ 57]\n",
      "  [ 52]\n",
      "  [ 77]\n",
      "  [ 71]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 64]\n",
      "  [ 37]\n",
      "  [173]\n",
      "  [ 95]\n",
      "  [ 72]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [ 81]\n",
      "  [ 86]\n",
      "  [160]\n",
      "  [ 20]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 89]\n",
      "  [ 78]\n",
      "  [ 81]\n",
      "  [ 83]\n",
      "  [ 80]\n",
      "  [ 74]\n",
      "  [ 20]\n",
      "  [177]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 49]\n",
      "  [ 77]\n",
      "  [ 91]\n",
      "  [200]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [ 95]\n",
      "  [ 86]\n",
      "  [ 88]\n",
      "  [ 88]\n",
      "  [ 89]\n",
      "  [ 88]\n",
      "  [ 89]\n",
      "  [ 88]\n",
      "  [ 83]\n",
      "  [ 89]\n",
      "  [ 86]\n",
      "  [  0]\n",
      "  [191]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 24]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [ 71]\n",
      "  [108]\n",
      "  [165]\n",
      "  [  0]\n",
      "  [ 24]\n",
      "  [ 57]\n",
      "  [ 52]\n",
      "  [ 57]\n",
      "  [ 60]\n",
      "  [ 60]\n",
      "  [ 60]\n",
      "  [ 63]\n",
      "  [ 63]\n",
      "  [ 77]\n",
      "  [ 89]\n",
      "  [ 52]\n",
      "  [  0]\n",
      "  [211]\n",
      "  [ 97]\n",
      "  [ 77]\n",
      "  [ 61]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 68]\n",
      "  [ 91]\n",
      "  [117]\n",
      "  [137]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [216]\n",
      "  [ 94]\n",
      "  [ 97]\n",
      "  [ 57]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [115]\n",
      "  [105]\n",
      "  [185]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  1]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [153]\n",
      "  [ 78]\n",
      "  [106]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 61]\n",
      "  [ 41]\n",
      "  [103]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [106]\n",
      "  [ 47]\n",
      "  [ 69]\n",
      "  [ 23]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]], shape=(28, 28, 1), dtype=uint8)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 10:51:25.585781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2024-02-12 10:51:25.586316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-02-12 10:51:25.628419: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# get first record\n",
    "for item in mnist_train.take(1):\n",
    "    print(type(item))\n",
    "    print(item.keys())\n",
    "    print(item['image'])\n",
    "    print(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='fashion_mnist',\n",
       "    full_name='fashion_mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
       "    \"\"\",\n",
       "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
       "    data_dir='/Users/medhaniesolomon/tensorflow_datasets/fashion_mnist/3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=29.45 MiB,\n",
       "    dataset_size=36.42 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
       "      author    = {Han Xiao and\n",
       "                   Kashif Rasul and\n",
       "                   Roland Vollgraf},\n",
       "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                   Algorithms},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1708.07747},\n",
       "      year      = {2017},\n",
       "      url       = {http://arxiv.org/abs/1708.07747},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1708.07747},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test, info = tfds.load(name=\"fashion_mnist\", with_info=\"true\")\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfds with keras\n",
    "(training_images, training_labels), (test_images, test_labels) = tfds.as_numpy(tfds.load('fashion_mnist', split=['train', 'test'],\n",
    "                                                                                         batch_size=-1, as_supervised=True))\n",
    "\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 790us/step - loss: 0.5270 - accuracy: 0.8138\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.3970 - accuracy: 0.8558\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.3626 - accuracy: 0.8669\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.3423 - accuracy: 0.8731\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.3271 - accuracy: 0.8799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x177993890>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 153.59 MiB (download: 153.59 MiB, generated: Unknown size, total: 153.59 MiB) to /Users/medhaniesolomon/tensorflow_datasets/horses_or_humans/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a296fbb0051d46acbf93f43efd17f019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e912243d4a4ac3949331f4892439a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d55ac6e1eb748bba878a69e015a2d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f957b1cf6841a6a298dde9529a36bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/1027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f15b8c0eed40c2a3d8fc96b810169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /Users/medhaniesolomon/tensorflow_datasets/horses_or_humans/3.0.0.incompleteXL21OK/horses_or_humans-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee26e661ac34ad0933753db6f37536b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2521005625a34fbdb27b3f3fd71d8f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /Users/medhaniesolomon/tensorflow_datasets/horses_or_humans/3.0.0.incompleteXL21OK/horses_or_humans-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset horses_or_humans downloaded and prepared to /Users/medhaniesolomon/tensorflow_datasets/horses_or_humans/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# horse or human data\n",
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
    "\n",
    "train_batches = data.shuffle(100).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                           input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                           input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                           input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                           input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:15:54.606121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [2]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-02-12 17:15:54.606980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [2]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 14s 129ms/step - loss: 10.1726 - accuracy: 0.8267\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 12s 114ms/step - loss: 0.1189 - accuracy: 0.9503\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 12s 113ms/step - loss: 0.0485 - accuracy: 0.9786\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 12s 117ms/step - loss: 0.0281 - accuracy: 0.9912\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 15s 148ms/step - loss: 0.1510 - accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 16s 152ms/step - loss: 0.0184 - accuracy: 0.9932\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 14s 135ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 14s 136ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 15s 145ms/step - loss: 5.2055e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 15s 146ms/step - loss: 1.6829e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.1527e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:18:54.260886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-02-12 17:18:54.261677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 14s 137ms/step - loss: 1.1527e-04 - accuracy: 1.0000 - val_loss: 4.2308 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "  1/103 [..............................] - ETA: 17s - loss: 8.8207e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:18:54.814671: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 14s 133ms/step - loss: 8.5516e-05 - accuracy: 1.0000 - val_loss: 4.2565 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "  1/103 [..............................] - ETA: 12s - loss: 7.3200e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:19:08.560259: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 13s 128ms/step - loss: 6.5667e-05 - accuracy: 1.0000 - val_loss: 4.2757 - val_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "  1/103 [..............................] - ETA: 12s - loss: 1.2415e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:19:21.740591: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 14s 132ms/step - loss: 5.1425e-05 - accuracy: 1.0000 - val_loss: 4.3097 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "  1/103 [..............................] - ETA: 19s - loss: 2.0696e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:19:35.342867: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 13s 128ms/step - loss: 4.1419e-05 - accuracy: 1.0000 - val_loss: 4.3422 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "  1/103 [..............................] - ETA: 13s - loss: 8.4561e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:19:48.645631: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 13s 129ms/step - loss: 3.3306e-05 - accuracy: 1.0000 - val_loss: 4.3738 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "  1/103 [..............................] - ETA: 12s - loss: 4.3177e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:20:01.892491: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 15s 147ms/step - loss: 2.7075e-05 - accuracy: 1.0000 - val_loss: 4.4045 - val_accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "  1/103 [..............................] - ETA: 12s - loss: 1.3333e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:20:17.009501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 13s 128ms/step - loss: 2.2641e-05 - accuracy: 1.0000 - val_loss: 4.4520 - val_accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "  1/103 [..............................] - ETA: 13s - loss: 6.0383e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:20:30.212988: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 14s 133ms/step - loss: 1.8837e-05 - accuracy: 1.0000 - val_loss: 4.4922 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "  1/103 [..............................] - ETA: 13s - loss: 3.9390e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:20:43.954200: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 14s 136ms/step - loss: 1.5614e-05 - accuracy: 1.0000 - val_loss: 4.5323 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:20:57.921956: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# validation data\n",
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
    "validation_batches = val_data.batch(32)\n",
    "history = model.fit(train_batches, epochs=10,\n",
    "validation_data = validation_batches, validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation\n",
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label\n",
    "\n",
    "train = data.map(augmentimages)\n",
    "train_batches = train.shuffle(100).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
